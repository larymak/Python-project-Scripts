import cv2
import numpy as np
import mediapipe as mp
from keras.models import  load_model
from keras.preprocessing import image
# from tensorflow.keras.utils import img_to_array
from PIL import Image, ImageOps

mpFaceDetection = mp.solutions.face_detection
mpDraw = mp.solutions.drawing_utils
faceDetection = mpFaceDetection.FaceDetection()

model = load_model('./Teachable ML Data/keras_model.h5')

cap = cv2.VideoCapture(1)

results_detect = {0:"üòÅ",1:"üò†",2:"‚òπÔ∏è",3:"üòä",4:"üò≤"}
results_detect_str = {0:"happy",1:"angry",2:"sad",3:"smile",4:"surprise"}

# pTime = 0
while cap.isOpened():
    _,img = cap.read()
    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
    results = faceDetection.process(imgRGB)
    if results.detections:
        ih,iw,ic = img.shape
        for id,detection in enumerate(results.detections):
            bBoxC = detection.location_data.relative_bounding_box
            bBox = int(bBoxC.xmin * iw),int(bBoxC.ymin * ih),int(bBoxC.width * iw),int(bBoxC.height * ih)
            # cv2.rectangle(img,bBox,(255,0,255),2)
            roi_gray = img[bBox[1]:bBox[1] + bBox[2], bBox[0]:bBox[0] + bBox[3]]
            roi_gray = cv2.resize(roi_gray, (224, 224))
            cv2.imwrite("image.jpg",roi_gray)


            data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)
            image = Image.open('image.jpg')
            size = (224, 224)
            image = ImageOps.fit(image, size, Image.ANTIALIAS)
            image_array = np.asarray(image)
            normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1
            data[0] = normalized_image_array
            prediction = model.predict(data)
            res = np.argmax(prediction)

            # predictions = np.argmax(model.predict(np.array([roi_gray])))
            # cv2.putText(img, results_detect[res], (150,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            temp_emotion = cv2.imread(f"./emotions/{results_detect_str[res]}.jfif")
            cv2.imshow("emotion", temp_emotion)
            print(results_detect[res])

    cv2.imshow("Image",img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        cv2.destroyAllWindows()
        break